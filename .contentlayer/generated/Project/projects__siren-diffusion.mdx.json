{
  "title": "SIREN & Diffusion Experiments",
  "slug": "siren-diffusion",
  "kind": "experiment",
  "year": "2024",
  "role": "Researcher – model training and evaluation",
  "themes": [
    "AI & Computational Media"
  ],
  "tags": [
    "SIREN",
    "diffusion-models",
    "generative",
    "implicit-representations"
  ],
  "heroMetric": "Small-scale experiments on learned representations and generative quality",
  "hook": "Experiments with SIREN-based implicit representations and diffusion models.",
  "featured": false,
  "order": 6,
  "body": {
    "raw": "\n\n## Overview\n\nTwo parallel experiments: reproducing SIREN implicit neural representations at high resolution and building diffusion-model sketches (DCGAN → Progressive GAN → diffusion) to study latent trajectories and editability. These exercises were part of coursework and self-directed research to gain intuition about continuous signal representations and modern generative priors. :contentReference[oaicite:11]{index=11}\n\n## SIREN (Implicit Representations)\n\n- Implemented sinusoidal representation networks (SIREN) to encode images at 1024×1024 resolution.\n- Explored positional encodings and activation scaling to stabilize training.\n- Observed excellent reconstruction fidelity for textures and high-frequency detail compared to baseline MLPs.\n\n## Diffusion & GAN Experiments\n\n- Re-implemented course assignments: DCGAN, Progressive GAN, and a basic diffusion pipeline on curated datasets.\n- Performed latent interpolations and denoising trajectories to understand mode coverage and sample diversity.\n- Benchmarked training behavior on an A100 and profiled memory/perf trade-offs to inform future model decisions.\n\n## Outcomes\n\n- The experiments improved practical know-how around model instabilities, training curricula for generative models, and how implicit representations can be integrated into larger graphics/vision pipelines (e.g., for texture compression or controllable editing in Happenstance / To Wilt).\n",
    "code": "var Component=(()=>{var u=Object.create;var o=Object.defineProperty;var m=Object.getOwnPropertyDescriptor;var h=Object.getOwnPropertyNames;var f=Object.getPrototypeOf,g=Object.prototype.hasOwnProperty;var x=(n,e)=>()=>(e||n((e={exports:{}}).exports,e),e.exports),v=(n,e)=>{for(var t in e)o(n,t,{get:e[t],enumerable:!0})},a=(n,e,t,s)=>{if(e&&typeof e==\"object\"||typeof e==\"function\")for(let r of h(e))!g.call(n,r)&&r!==t&&o(n,r,{get:()=>e[r],enumerable:!(s=m(e,r))||s.enumerable});return n};var b=(n,e,t)=>(t=n!=null?u(f(n)):{},a(e||!n||!n.__esModule?o(t,\"default\",{value:n,enumerable:!0}):t,n)),N=n=>a(o({},\"__esModule\",{value:!0}),n);var d=x((y,l)=>{l.exports=_jsx_runtime});var E={};v(E,{default:()=>p,frontmatter:()=>w});var i=b(d()),w={title:\"SIREN & Diffusion Experiments\",slug:\"siren-diffusion\",kind:\"experiment\",year:\"2024\",role:\"Researcher \\u2013 model training and evaluation\",themes:[\"AI & Computational Media\"],tags:[\"SIREN\",\"diffusion-models\",\"generative\",\"implicit-representations\"],heroMetric:\"Small-scale experiments on learned representations and generative quality\",hook:\"Experiments with SIREN-based implicit representations and diffusion models.\",featured:!1,order:6};function c(n){let e={h2:\"h2\",li:\"li\",p:\"p\",ul:\"ul\",...n.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(e.h2,{children:\"Overview\"}),`\n`,(0,i.jsxs)(e.p,{children:[\"Two parallel experiments: reproducing SIREN implicit neural representations at high resolution and building diffusion-model sketches (DCGAN \\u2192 Progressive GAN \\u2192 diffusion) to study latent trajectories and editability. These exercises were part of coursework and self-directed research to gain intuition about continuous signal representations and modern generative priors. :contentReference[oaicite:11]\",index=11]}),`\n`,(0,i.jsx)(e.h2,{children:\"SIREN (Implicit Representations)\"}),`\n`,(0,i.jsxs)(e.ul,{children:[`\n`,(0,i.jsx)(e.li,{children:\"Implemented sinusoidal representation networks (SIREN) to encode images at 1024\\xD71024 resolution.\"}),`\n`,(0,i.jsx)(e.li,{children:\"Explored positional encodings and activation scaling to stabilize training.\"}),`\n`,(0,i.jsx)(e.li,{children:\"Observed excellent reconstruction fidelity for textures and high-frequency detail compared to baseline MLPs.\"}),`\n`]}),`\n`,(0,i.jsx)(e.h2,{children:\"Diffusion & GAN Experiments\"}),`\n`,(0,i.jsxs)(e.ul,{children:[`\n`,(0,i.jsx)(e.li,{children:\"Re-implemented course assignments: DCGAN, Progressive GAN, and a basic diffusion pipeline on curated datasets.\"}),`\n`,(0,i.jsx)(e.li,{children:\"Performed latent interpolations and denoising trajectories to understand mode coverage and sample diversity.\"}),`\n`,(0,i.jsx)(e.li,{children:\"Benchmarked training behavior on an A100 and profiled memory/perf trade-offs to inform future model decisions.\"}),`\n`]}),`\n`,(0,i.jsx)(e.h2,{children:\"Outcomes\"}),`\n`,(0,i.jsxs)(e.ul,{children:[`\n`,(0,i.jsx)(e.li,{children:\"The experiments improved practical know-how around model instabilities, training curricula for generative models, and how implicit representations can be integrated into larger graphics/vision pipelines (e.g., for texture compression or controllable editing in Happenstance / To Wilt).\"}),`\n`]})]})}function p(n={}){let{wrapper:e}=n.components||{};return e?(0,i.jsx)(e,{...n,children:(0,i.jsx)(c,{...n})}):c(n)}return N(E);})();\n;return Component;"
  },
  "_id": "projects/siren-diffusion.mdx",
  "_raw": {
    "sourceFilePath": "projects/siren-diffusion.mdx",
    "sourceFileName": "siren-diffusion.mdx",
    "sourceFileDir": "projects",
    "contentType": "mdx",
    "flattenedPath": "projects/siren-diffusion"
  },
  "type": "Project",
  "url": "/projects/siren-diffusion"
}